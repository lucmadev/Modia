# üìã AGENTS.md - Gu√≠a de Referencia R√°pida para Modia

> **Prop√≥sito**: Este documento permite entender r√°pidamente el proyecto Modia sin tener que releer todo el c√≥digo cada vez.

---

## üéØ ¬øQu√© es Modia?

**Modia** es un **copiloto t√©cnico local** para desarrollo de plugins de **Hytale**, basado en **RAG (Retrieval-Augmented Generation)** con memoria conversacional expl√≠cita.

**Objetivo**: Responder r√°pido, directo y con criterio t√©cnico sobre el c√≥digo de HytaleServer, sin tener que releer el c√≥digo del servidor repetidamente.

**Estado**: Early Access (el juego Hytale est√° en early access, el proyecto tambi√©n).

---

## üèóÔ∏è Arquitectura y Stack

### Stack Tecnol√≥gico
- **Python 3.10+**
- **Ollama** (LLM + embeddings)
- **LangChain** (orquestaci√≥n)
- **ChromaDB** (base de datos vectorial)

### Modelos Recomendados
- **LLM**: `llama3.1:8b`
- **Embeddings**: `nomic-embed-text`

### Componentes Principales

1. **`modia-chat.py`**: Script principal del chat interactivo
2. **`utils/extractChunks.py`**: Extrae chunks relevantes del c√≥digo descompilado
3. **`utils/buildDB.py`**: Construye la base de datos vectorial con ChromaDB
4. **`Makefile`** / **`build.ps1`**: Scripts de build para Linux/Mac y Windows

---

## üîÑ Flujo de Trabajo

### 1. Setup Inicial (Indexaci√≥n)

**Proceso completo**:
```
HytaleServer.jar ‚Üí Descompilaci√≥n (CFR) ‚Üí Extracci√≥n de chunks ‚Üí Base vectorial
```

**Pasos detallados**:

1. **Colocar JAR**: `server/HytaleServer.jar`
2. **Descompilar**: Usa CFR (Java Decompiler) para extraer c√≥digo fuente Java
   - Linux/Mac: `make decompile`
   - Windows: `./build.ps1` (incluye descompilaci√≥n)
3. **Extraer chunks**: Filtra archivos `.java` relevantes (keywords: "event", "plugin", "api", "player", "server")
   - Script: `utils/extractChunks.py`
   - Output: `chunks.txt`
   - L√≠mite: 6000 caracteres por archivo
4. **Construir DB**: Crea base vectorial con ChromaDB
   - Script: `utils/buildDB.py`
   - Chunk size: 800 caracteres
   - Overlap: 200 caracteres
   - Output: `./hytale_db/`

### 2. Uso del Chat

**Ejecuci√≥n**:
- Linux/Mac: `python modia-chat.py`
- Windows: `python ./modia-chat.py`

**Flujo de cada pregunta**:
1. Usuario escribe pregunta
2. B√∫squeda sem√°ntica en ChromaDB (top 5 documentos)
3. Construcci√≥n de prompt con:
   - System prompt (reglas estrictas)
   - Memoria conversacional (√∫ltimos mensajes relevantes)
   - Contexto t√©cnico (documentos encontrados)
   - Pregunta del usuario
4. Invocaci√≥n del LLM
5. Almacenamiento selectivo en memoria (si es relevante)
6. Resumen autom√°tico cuando memoria alcanza MAX_MEMORY (6 mensajes)

---

## üìÅ Estructura de Archivos

```
Modia/
‚îú‚îÄ‚îÄ modia-chat.py          # Script principal del chat
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ extractChunks.py   # Extrae chunks relevantes del c√≥digo
‚îÇ   ‚îî‚îÄ‚îÄ buildDB.py         # Construye la base vectorial
‚îú‚îÄ‚îÄ server/
‚îÇ   ‚îî‚îÄ‚îÄ HytaleServer.jar   # JAR a descompilar (debe estar presente)
‚îú‚îÄ‚îÄ hytale_src/            # C√≥digo descompilado (generado)
‚îú‚îÄ‚îÄ hytale_db/             # Base de datos vectorial (generada)
‚îú‚îÄ‚îÄ chunks.txt             # Chunks extra√≠dos (generado)
‚îú‚îÄ‚îÄ libs/
‚îÇ   ‚îî‚îÄ‚îÄ cfr.jar            # Java decompiler (descargado autom√°ticamente)
‚îú‚îÄ‚îÄ Makefile               # Build para Linux/Mac
‚îú‚îÄ‚îÄ build.ps1              # Build para Windows
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îî‚îÄ‚îÄ venv/                  # Entorno virtual Python
```

---

## üß† Caracter√≠sticas T√©cnicas Clave

### Memoria Conversacional

- **NO depende de memoria impl√≠cita del modelo**
- **Almacenamiento selectivo**: Solo mensajes t√©cnicos relevantes (keywords: "entity", "trigger", "event", "api", "server", "engine", "lifecycle", "mod", "hook")
- **L√≠mite**: MAX_MEMORY = 6 mensajes
- **Resumen autom√°tico**: Cuando se alcanza el l√≠mite, se genera un resumen t√©cnico de 5 puntos y se reemplaza la memoria

### Modo Explicaci√≥n (Natural)

- **Sin comandos especiales**: Detecta autom√°ticamente cuando el usuario pide explicaciones
- **Triggers**: "explicame", "c√≥mo funciona", "no entiendo", "qu√© hace", "explain", "how does it work", etc.
- **Comportamiento**: Activa modo explicaci√≥n con m√°s detalle, pero sin revelar contexto interno

### System Prompt

**Reglas absolutas**:
- Responder SOLO con la salida final
- NO revelar historia, contexto o razonamiento interno
- NO repetir o describir el contexto proporcionado
- NO usar t√≠tulos, secciones o headers
- NO usar calificadores como "seg√∫n el contexto"

**Comportamiento**:
- Proporcionar respuesta incluso si la informaci√≥n es parcial
- Inferir detalles usando patrones comunes de game engines
- Si una caracter√≠stica no existe, decirlo claramente
- Lenguaje t√©cnico, directo y conciso
- Enfoque orientado a modding

---

## üó∫Ô∏è Roadmap (Tareas Pendientes)

Seg√∫n README.md l√≠neas 130-137:

- [ ] **Convertir el chat en CLI**: Actualmente es un script Python interactivo b√°sico
- [ ] **Agregar comandos √∫tiles**: Como `/explain` o `/raw` (aunque ya hay modo explicaci√≥n natural)
- [ ] **Persistencia de memoria en disco**: Actualmente la memoria es solo en memoria (se pierde al cerrar)
- [ ] **Autocompletado de comandos**: Mejorar UX del CLI
- [ ] **Flags `--no-rag` / `--rag-only`**: Permitir desactivar RAG o usar solo RAG
- [ ] **Perfiles por proyecto**: M√∫ltiples configuraciones/base de datos por proyecto
- [ ] **Empaquetado como binario**: Distribuci√≥n m√°s f√°cil (probablemente con PyInstaller o similar)

---

## üîß Detalles de Implementaci√≥n

### Extracci√≥n de Chunks (`utils/extractChunks.py`)

- **Filtrado**: Solo archivos `.java` que contengan keywords en la ruta
- **Keywords**: `["event", "plugin", "api", "player", "server"]`
- **L√≠mite por archivo**: 6000 caracteres (primeros 6000)
- **Output**: Formato `--- FILE: {path} ---\n{code}`

### Construcci√≥n de DB (`utils/buildDB.py`)

- **Loader**: `TextLoader` para `chunks.txt`
- **Splitter**: `RecursiveCharacterTextSplitter`
  - Chunk size: 800
  - Overlap: 200
- **Embeddings**: `OllamaEmbeddings` con `nomic-embed-text`
- **Vector Store**: `Chroma` con persistencia en `./hytale_db`

### Chat Principal (`modia-chat.py`)

- **B√∫squeda**: `db.similarity_search(q, k=5)` - top 5 documentos
- **LLM**: `ChatOllama` con `llama3.1:8b`, temperature=0.1
- **Memoria**: Lista de dicts `[{"role": "user/assistant", "content": "..."}]`
- **Normalizaci√≥n**: Maneja diferentes formatos de respuesta del LLM (string, list, dict)

### Funci√≥n `should_store(text)`

- **Filtros**: 
  - Texto debe tener al menos 40 caracteres
  - Debe contener keywords t√©cnicos relevantes
- **Keywords**: `["entity", "entidad", "trigger", "evento", "api", "event", "server", "engine", "lifecycle", "mod", "hook"]`

---

## ‚ö†Ô∏è Notas Importantes

1. **Ollama debe estar corriendo**: El proyecto depende de Ollama local
2. **Modelos deben estar descargados**: `llama3.1:8b` y `nomic-embed-text`
3. **Java requerido**: Para descompilar el JAR con CFR
4. **Proyecto no oficial**: No afiliado con Hypixel Studios, uso educativo/desarrollo
5. **Memoria no persistente**: Actualmente se pierde al cerrar el chat

---

## üöÄ Comandos √ötiles

### Setup Completo (Windows)
```powershell
./build.ps1
```

### Setup Completo (Linux/Mac)
```bash
make install  # Instala dependencias
make decompile  # Descompila JAR
make chunks    # Extrae chunks
make db        # Construye DB
```

### Ejecutar Chat
```bash
python modia-chat.py
```

### Limpiar
```bash
make clean  # Elimina venv y hytale_src
```

---

## üìù Convenciones del C√≥digo

- **Espa√±ol**: Comentarios y mensajes en espa√±ol
- **Tipo hints**: Uso de `typing` para tipos (List, Dict)
- **Funciones puras**: `should_store()`, `format_memory()`, `is_explain_mode()`, `normalize_llm_output()`
- **Variables globales**: `memory`, `embeddings`, `db`, `llm` (configuraci√≥n compartida)

---

## üîç Puntos de Extensi√≥n Futuros

1. **CLI mejorado**: Usar `click` o `typer` para comandos estructurados
2. **Persistencia**: Guardar memoria en JSON/Pickle en disco
3. **Configuraci√≥n**: Archivo de config (modelos, paths, par√°metros)
4. **M√∫ltiples DBs**: Soporte para diferentes versiones de HytaleServer
5. **Streaming**: Respuestas en tiempo real del LLM
6. **Logging**: Sistema de logs para debugging

---

*√öltima actualizaci√≥n: Basado en an√°lisis del c√≥digo actual (2024)*


